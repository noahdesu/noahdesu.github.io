<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Hadoop on Ceph: Diving In</title>
  <meta name="description" content="It has been possible for several years now to run Hadoop on top of the Cephfile system using a shim layer that maps between the HDFS abstraction and theunder...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://noahdesu.github.io/2015/07/12/hadoop-ceph-diving-in.html">
  <link rel="alternate" type="application/rss+xml" title="makedist" href="http://noahdesu.github.io/feed.xml" />
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">makedist</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
        
          
        
          
          <a class="page-link" href="/legion.html">Legion</a>
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Hadoop on Ceph: Diving In</h1>
    <p class="post-meta">Jul 12, 2015
    </p>
    <a href="https://twitter.com/share" class="twitter-share-button"{count} data-via="noahdesu">Tweet</a><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </header>

  <article class="post-content">
    <p>It has been possible for several years now to run Hadoop on top of the Ceph
file system using a shim layer that maps between the HDFS abstraction and the
underlying Ceph file interface. Since then bug fixes and performance
enhancements have found their way into the shim, but usability has remained a
sore area primarily due to the lack of documentation, and low-level setup
required in many instances. But no more.</p>

<p>This post marks the beginning of a series of posts on using Hadoop on top of
Ceph. These posts are not meant to be a substitute for the official
documentation. But, that documentation doesn&#39;t exist, you say? Well, that&#39;s the
journey I&#39;m starting now, the culmination of which will be a set of easy to use
tools and documentation.</p>

<p>It&#39;s been a while since I setup Hadoop on top of Ceph. So let&#39;s jump into the
deep end and see what happens. In these posts I won&#39;t dive much (if at all)
into the installation details of Ceph. For that I&#39;ll refer the reader to
<a href="http://ceph.com/docs">http://ceph.com/docs</a> which contains excellent documentation on getting started
with the Ceph storage system. The Ceph file system is still in development, and
its documentation is sparse and in flux, but the official Ceph documentation
has enough information to get you up and running with the file system. I&#39;ll
generally post the version of software and configuration of the Ceph file
system, and highlight anything of specific importance.</p>

<h1>Ceph Installation</h1>

<p>Here&#39;s the basic setup. Everything is done with <code>ceph-deploy</code>.</p>

<ul>
<li>Fedora Server 22</li>
<li>Ceph development installation

<ul>
<li>ceph version 9.0.1-1455-g6612058 (661205899be3e3f7b53682a3b87c1340e395b62e)</li>
</ul></li>
<li>Single host, 1 monitor, 1 OSD</li>
</ul>

<p>Ceph is installed, and <code>ceph status</code> reports:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">[nwatkins@localhost cluster]$ sudo ceph status
    cluster e3f30405-0b81-4c1c-a811-91b68b076644
     health HEALTH_OK
     monmap e1: 1 mons at {localhost=[::1]:6789/0}
            election epoch 2, quorum 0 localhost
     osdmap e5: 1 osds: 1 up, 1 in
      pgmap v7: 64 pgs, 1 pools, 0 bytes data, 0 objects
            6715 MB used, 31669 MB / 38385 MB avail
                  64 active+clean
</code></pre></div>
<h2>File System Configuration</h2>

<p>The Ceph file system consists of one metadata pool and one data pool:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">[nwatkins@localhost cluster]$ ceph mds stat
e5: 1/1/1 up {0=localhost=up:active}

[nwatkins@localhost cluster]$ ceph fs ls
name: cephfs, metadata pool: cephfs_metadata, data pools: [cephfs_data ]
</code></pre></div>
<p>The current Ceph installation has a single administrative user. We&#39;ll focus on
this particular configuration and examine using custom users later, including
the implications on Hadoop configuration.</p>

<h1>Hadoop Setup</h1>

<p>I&#39;m following the basic single-node Hadoop setup.</p>

<ul>
<li>java-1.8.0-openjdk</li>
<li>Hadoop 2.7.1 binary</li>
<li>set JAVA HOME to /usr/lib/jvm/jre</li>
</ul>

<p>Right out of the box Hadoop should has some basic functionality. <code>fs -ls</code> lists
the current directory on the local file system. The goal of this post is to
setup Hadoop so that this command will list directory contents in the Ceph file
system.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">[nwatkins@localhost hadoop-2.7.1]$ bin/hadoop fs -ls
Found 10 items
-rw-r--r--   1 nwatkins nwatkins      15429 2015-06-29 00:15 LICENSE.txt
-rw-r--r--   1 nwatkins nwatkins        101 2015-06-29 00:15 NOTICE.txt
-rw-r--r--   1 nwatkins nwatkins       1366 2015-06-29 00:15 README.txt
drwxr-xr-x   - nwatkins nwatkins       4096 2015-06-29 00:15 bin
drwxr-xr-x   - nwatkins nwatkins         19 2015-06-29 00:15 etc
drwxr-xr-x   - nwatkins nwatkins        101 2015-06-29 00:15 include
drwxr-xr-x   - nwatkins nwatkins         19 2015-06-29 00:15 lib
drwxr-xr-x   - nwatkins nwatkins       4096 2015-06-29 00:15 libexec
drwxr-xr-x   - nwatkins nwatkins       4096 2015-06-29 00:15 sbin
drwxr-xr-x   - nwatkins nwatkins         29 2015-06-29 00:15 share
</code></pre></div>
<p>In a Hadoop setup that runs on top of HDFS this would be the point at which
HDFS is setup, and Hadoop is configured to run on top of HDFS. For instance,
a basic Hadoop tutorial will use a configuration similar to this:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre></div>
<p>Instead of point Hadoop at HDFS, we want to point it at Ceph.</p>

<h1>Hadoop/Ceph Setup</h1>

<p>Add the following to the <code>core-site.xml</code> Hadoop configuration file. The
<code>fs.defaultFS</code> generally should point at a Ceph monitor with the default Ceph
port. There are a variety of configuration options, but this is common. The
other configuration properties are used to tell Hadoop the classpath of the
shim layer.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;fs.defaultFS&lt;/name&gt;
    &lt;value&gt;ceph://localhost:6789/&lt;/value&gt;
  &lt;/property&gt;

  &lt;!-- default 1.x implementation --&gt;
  &lt;property&gt;
    &lt;name&gt;fs.ceph.impl&lt;/name&gt;
    &lt;value&gt;org.apache.hadoop.fs.ceph.CephFileSystem&lt;/value&gt;
  &lt;/property&gt;

  &lt;!-- default implementation --&gt;
  &lt;property&gt;
    &lt;name&gt;fs.AbstractFileSystem.ceph.impl&lt;/name&gt;
    &lt;value&gt;org.apache.hadoop.fs.ceph.CephFs&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</code></pre></div>
<p>If we repeat the <code>fs -ls</code> command Hadoop complains that it cannot find the Ceph file system shim.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">[nwatkins@localhost hadoop-2.7.1]$ bin/hadoop fs -ls
-ls: Fatal internal error
java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.ceph.CephFileSystem not found
        at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2195)
        at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2638)
        at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2651)
        at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:92)
</code></pre></div>
<p>The shim layer can be obtained from <a href="https://github.com/ceph/cephfs-hadoop.git">https://github.com/ceph/cephfs-hadoop.git</a>. Once
cloned, run <code>mvn package</code>. This hits us with a new error which basically says that
the Java bindings for <code>libcephfs</code> cannot be found.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">Tests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 0.552 sec &lt;&lt;&lt; FAILURE!
org.apache.hadoop.fs.test.unit.HcfsUmaskTest  Time elapsed: 0.551 sec  &lt;&lt;&lt; ERROR!
java.lang.UnsatisfiedLinkError: no cephfs_jni in java.library.path
        at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1865)
        at java.lang.Runtime.loadLibrary0(Runtime.java:870)
        at java.lang.System.loadLibrary(System.java:1122)
        at com.ceph.fs.CephNativeLoader.&lt;clinit&gt;(CephNativeLoader.java:28)
        at com.ceph.fs.CephMount.&lt;clinit&gt;(CephMount.java:88)
</code></pre></div>
<p>That&#39;s an easy fix. Install with <code>ceph-deploy</code>:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">ceph-deploy pkg --install cephfs-java localhost
</code></pre></div>
<p>That will put some bits in the local file system:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">/usr/lib64/libcephfs_jni.so.1
/usr/lib64/libcephfs_jni.so.1.0.0
/usr/share/java/libcephfs-test.jar
/usr/share/java/libcephfs.jar
</code></pre></div>
<p>Unfortunately Maven will not look here. So copy the installed file <code>libcephfs.jar</code> into
<code>src/main/resources</code> in the <code>cephfs-hadoop</code> tree. Run the Maven package command again, but
skip the tests (this is additional setup we don&#39;t want to deal with right now):</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">mvn -Dmaven.test.skip=true package
</code></pre></div>
<p>This should succeed:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">[nwatkins@localhost cephfs-hadoop]$ ls -l target/
total 120
drwxrwxr-x. 3 nwatkins nwatkins  4096 Jul 12 20:32 apidocs
-rw-rw-r--. 1 nwatkins nwatkins 30369 Jul 12 20:31 cephfs-hadoop-0.80.6.jar
-rw-rw-r--. 1 nwatkins nwatkins 53428 Jul 12 20:32 cephfs-hadoop-0.80.6-javadoc.jar
-rw-rw-r--. 1 nwatkins nwatkins 26455 Jul 12 20:31 cephfs-hadoop-0.80.6-sources.jar
drwxrwxr-x. 3 nwatkins nwatkins    36 Jul 12 20:31 classes
drwxrwxr-x. 2 nwatkins nwatkins    69 Jul 12 20:32 javadoc-bundle-options
drwxrwxr-x. 2 nwatkins nwatkins    27 Jul 12 20:31 maven-archiver
drwxrwxr-x. 3 nwatkins nwatkins    34 Jul 12 20:31 maven-status
</code></pre></div>
<p>Now that we have the shim layer, we need to add it to the Hadoop CLASSPATH.
Copy over <code>target/libcephfs-hadoop-0.80.6.jar</code> from <code>cephfs-hadoop</code> into <code>hadoop/lib</code>, and do the same for
the installed <code>libcephfs.jar</code> file located at <code>/usr/share/java/libcephfs.jar</code>. Now setup the
environment so Hadoop will pick up these dependencies.</p>

<p>into <code>hadoop/lib</code>, and setup the environment:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">export HADOOP_CLASSPATH=$HOME/hadoop-2.7.1/lib/cephfs-hadoop-0.80.6.jar
export HADOOP_CLASSPATH=$HOME/hadoop-2.7.1/lib/libcephfs.jar:$HADOOP_CLASSPATH
</code></pre></div>
<p>Unfortunately Hadoop doesn&#39;t always look at the system directories for these
dependencies.  Running again you may see something like this which is saying
that the native (i.e. C++) bits can&#39;t be found.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">[nwatkins@localhost hadoop-2.7.1]$ bin/hadoop fs -ls                                                                                                                                                   
Exception in thread &quot;main&quot; java.lang.UnsatisfiedLinkError: no cephfs_jni in java.library.path
        at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1865)
        at java.lang.Runtime.loadLibrary0(Runtime.java:870)
        at java.lang.System.loadLibrary(System.java:1122)
        at com.ceph.fs.CephNativeLoader.&lt;clinit&gt;(CephNativeLoader.java:28)
        at com.ceph.fs.CephMount.&lt;clinit&gt;(CephMount.java:97)
</code></pre></div>
<p>To resolve this, copy the <code>/usr/lib64/libcephfs_jni.*</code> into <code>hadoop/lib/native</code>.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">natkins@localhost hadoop-2.7.1]$ ls -l /usr/lib64/libcephfs_jni*
lrwxrwxrwx. 1 root root     22 Jul 10 16:20 /usr/lib64/libcephfs_jni.so.1 -&gt; libcephfs_jni.so.1.0.0
-rwxr-xr-x. 1 root root 106544 Jul 10 16:39 /usr/lib64/libcephfs_jni.so.1.0.0
</code></pre></div>
<p>The Java bindings for <code>libcephfs</code> are setup to look for <code>libcephfs_jni.so</code>, so add a symbolic link:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">[nwatkins@localhost native]$ ln -s libcephfs_jni.so.1.0.0 libcephfs_jni.so
[nwatkins@localhost native]$ ls -l
total 5144
lrwxrwxrwx. 1 nwatkins nwatkins      22 Jul 12 21:01 libcephfs_jni.so -&gt; libcephfs_jni.so.1.0.0
-rwxr-xr-x. 1 nwatkins nwatkins  106544 Jul 12 21:01 libcephfs_jni.so.1
-rwxr-xr-x. 1 nwatkins nwatkins  106544 Jul 12 21:01 libcephfs_jni.so.1.0.0
</code></pre></div>
<p>Now we should be all set. Run <code>fs -ls</code> again:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">[nwatkins@localhost hadoop-2.7.1]$ bin/hadoop fs -ls
ls: `.&#39;: No such file or directory
</code></pre></div>
<p>Hadoop will default to looking at the user&#39;s home directory, but this doesn&#39;t yet exist.
We can stick some stuff in the root directory to verify:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">[nwatkins@localhost hadoop-2.7.1]$ bin/hadoop fs -ls /
[nwatkins@localhost hadoop-2.7.1]$ bin/hadoop fs -put etc/hadoop/core-site.xml /
15/07/12 21:03:01 INFO ceph.CephFileSystem: selectDataPool path=ceph://localhost:6789/core-site.xml._COPYING_ pool:repl=cephfs_data:1 wanted=3
[nwatkins@localhost hadoop-2.7.1]$ bin/hadoop fs -ls /
Found 1 items
-rw-r--r--   1 nwatkins       4269 2015-07-12 21:03 /core-site.xml
</code></pre></div>
<p>Success. Now to make that a hell of a lot easier :)</p>

  </article>

  <section id="disqus_thread"></section>

<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'noahdesugithubcom'; // required: replace example with your forum shortname
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">makedist</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li>makedist</li>
          <li><a href="mailto:noahwatkins@gmail.com">noahwatkins@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/noahdesu">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>

              <span class="username">noahdesu</span>
            </a>
          </li>
          

          
          <li>
            <a href="https://twitter.com/noahdesu">
              <span class="icon  icon--twitter">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                  c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
                </svg>
              </span>

              <span class="username">noahdesu</span>
            </a>
          </li>
          
        </ul>
      </div>

      <div class="footer-col  footer-col-3">
        <p class="text">Notes on programming, research, and other interests.
</p>
      </div>
    </div>

  </div>

</footer>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-37966177-1', 'auto');
  ga('send', 'pageview');
</script>

  </body>

</html>
