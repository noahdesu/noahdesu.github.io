<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Legion Runtime Class #6: Processor, Memory, and Message Managers</title>
  <meta name="description" content="About Legion Runtime Class">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://noahdesu.github.io/2015/02/16/legion-runtime-services-managers.html">
  <link rel="alternate" type="application/rss+xml" title="makedist" href="http://noahdesu.github.io/feed.xml" />
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">makedist</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
        
          
        
          
          <a class="page-link" href="/legion.html">Legion</a>
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Legion Runtime Class #6: Processor, Memory, and Message Managers</h1>
    <p class="post-meta">Feb 16, 2015
    </p>
    <a href="https://twitter.com/share" class="twitter-share-button"{count} data-via="noahdesu">Tweet</a><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </header>

  <article class="post-content">
    <h1>About Legion Runtime Class</h1>

<p>These notes are closely based on the set
of <a href="http://www.youtube.com/playlist?list=PLUNK9XcztK7xjXfppL9hIpVv2ukp7A4tG">Legion Runtime
Class</a>
videos produced by the <a href="http://legion.stanford.edu">Legion</a> developers. They are my own notes and code walks, and any
errors or things that are just plain wrong represent my own mistakes.</p>

<p>Today&#39;s notes are based on the following video:</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Dwxyp5U0_Rg?list=PLUNK9XcztK7xjXfppL9hIpVv2ukp7A4tG" frameborder="0" allowfullscreen></iframe>

<h2>Overview</h2>

<p>The notes for this class with cover some of the hardware resource managers that the high-level runtime service provides as some of its internal services. The managers covered at the <code>MemoryManager</code>, <code>MessageManager</code>, and the <code>ProcessorManager</code>.</p>

<h1>Memory Manager</h1>

<p>The <code>MemoryManager</code> tracks the usage of memories provided by the low-level runtime. An <code>MemoryManager</code> instance is created for every low-level memory, including both local and remote memories. Instances of the manager are instantiated lazily since there may be thousands of distinct memories in a large machine with tasks on nodes accessing only a subset of those memories. You&#39;ll find the <code>MemoryManager</code> declaration in <code>runtime.h</code>:</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++"><span class="cm">/**</span>
<span class="cm"> * \class MemoryManager</span>
<span class="cm"> * The goal of the memory manager is to keep track of all of</span>
<span class="cm"> * the physical instances that the runtime knows about in various</span>
<span class="cm"> * memories throughout the system.  This will then allow for</span>
<span class="cm"> * feedback when mapping to know when memories are nearing</span>
<span class="cm"> * their capacity.</span>
<span class="cm"> */</span>
<span class="k">class</span> <span class="nc">MemoryManager</span> <span class="p">{</span>
  <span class="k">public</span><span class="o">:</span>
    <span class="n">MemoryManager</span><span class="p">(</span><span class="n">Memory</span> <span class="n">mem</span><span class="p">,</span> <span class="n">Runtime</span> <span class="o">*</span><span class="n">rt</span><span class="p">);</span>
    <span class="n">MemoryManager</span><span class="p">(</span><span class="k">const</span> <span class="n">MemoryManager</span> <span class="o">&amp;</span><span class="n">rhs</span><span class="p">);</span>
    <span class="o">~</span><span class="n">MemoryManager</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>
<span class="p">...</span>
</code></pre></div>
<p>During physical dependence analysis instances are created. When this is done the high-level runtime will register that the instance has been created with a memory manager. This is the entrance point for registering physical instances with a memory manager:</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++"><span class="kt">void</span> <span class="n">Runtime</span><span class="o">::</span><span class="n">allocate_physical_instance</span><span class="p">(</span><span class="n">PhysicalManager</span> <span class="o">*</span><span class="n">instance</span><span class="p">)</span>
<span class="p">{</span>
  <span class="n">find_memory</span><span class="p">(</span><span class="n">instance</span><span class="o">-&gt;</span><span class="n">memory</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">allocate_physical_instance</span><span class="p">(</span><span class="n">instance</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>
<p>The <code>find_memory</code> method is used to find the memory manager for a particular memory, and is also responsible for the lazy instantiation of new memory managers. The <code>Memory</code> object represented here is a low-level memory (i.e. a small handle), and a map from the memory handle to the manager is maintained by the runtime. First we check if a manager already exists for the memory in the mapping, and if not, a new memory manager is created and cached:</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++"><span class="n">MemoryManager</span><span class="o">*</span> <span class="n">Runtime</span><span class="o">::</span><span class="n">find_memory</span><span class="p">(</span><span class="n">Memory</span> <span class="n">mem</span><span class="p">)</span>
<span class="p">{</span>
  <span class="n">AutoLock</span> <span class="n">m_lock</span><span class="p">(</span><span class="n">memory_manager_lock</span><span class="p">);</span>

  <span class="c1">// already have a manager for this memory?</span>
  <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">Memory</span><span class="p">,</span><span class="n">MemoryManager</span><span class="o">*&gt;::</span><span class="n">const_iterator</span> <span class="n">finder</span> <span class="o">=</span> <span class="n">memory_managers</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">mem</span><span class="p">);</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">finder</span> <span class="o">!=</span> <span class="n">memory_managers</span><span class="p">.</span><span class="n">end</span><span class="p">())</span>
      <span class="k">return</span> <span class="n">finder</span><span class="o">-&gt;</span><span class="n">second</span><span class="p">;</span>

  <span class="c1">// lazy creation</span>
  <span class="n">MemoryManager</span> <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MemoryManager</span><span class="p">(</span><span class="n">mem</span><span class="p">,</span> <span class="k">this</span><span class="p">);</span>
  <span class="n">memory_managers</span><span class="p">[</span><span class="n">mem</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="p">;</span>
  <span class="k">return</span> <span class="n">result</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>
<p>Once we get back the memory manager instance in the runtime, <code>allocate_physical_instance</code> on the manager instance is called.</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++"><span class="kt">void</span> <span class="n">MemoryManager</span><span class="o">::</span><span class="n">allocate_physical_instance</span><span class="p">(</span><span class="n">PhysicalManager</span> <span class="o">*</span><span class="n">manager</span><span class="p">)</span>
<span class="p">{</span>
  <span class="k">const</span> <span class="kt">size_t</span> <span class="n">inst_size</span> <span class="o">=</span> <span class="n">manager</span><span class="o">-&gt;</span><span class="n">get_instance_size</span><span class="p">();</span>

  <span class="n">AutoLock</span> <span class="nf">m_lock</span><span class="p">(</span><span class="n">manager_lock</span><span class="p">);</span>

  <span class="c1">// track capacity</span>
  <span class="n">remaining_capacity</span> <span class="o">-=</span> <span class="n">inst_size</span><span class="p">;</span>

  <span class="c1">// categorize the memory into the correct data structure</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">manager</span><span class="o">-&gt;</span><span class="n">is_reduction_manager</span><span class="p">())</span> <span class="p">{</span>
    <span class="n">ReductionManager</span> <span class="o">*</span><span class="n">reduc</span> <span class="o">=</span> <span class="n">manager</span><span class="o">-&gt;</span><span class="n">as_reduction_manager</span><span class="p">();</span>
    <span class="n">reduction_instances</span><span class="p">[</span><span class="n">reduc</span><span class="p">]</span> <span class="o">=</span> <span class="n">inst_size</span><span class="p">;</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="n">InstanceManager</span> <span class="o">*</span><span class="n">inst</span> <span class="o">=</span> <span class="n">manager</span><span class="o">-&gt;</span><span class="n">as_instance_manager</span><span class="p">();</span>
    <span class="n">physical_instances</span><span class="p">[</span><span class="n">inst</span><span class="p">]</span> <span class="o">=</span> <span class="n">inst_size</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>In addition to notifying the memory manager about allocated physical instances, there are additional calls for freeing instances. It is important to note that memory managers represent an incomplete view of the memory being used by the low-level runtime system. The reason for this is that only the allocations performed on the local node are tracked, even though a memory may have memory allocated within it from other nodes in the machine. The partial view is incomplete, but it is helpful for mappers when making decisions.</p>

<h1>Message Manager</h1>

<p>The <code>MessageManager</code> provides an endpoint for communicating with other remote nodes in the system. There is <code>MessageManager</code> instance created for every other node in the machine. The manager provides an in-order channel for communicating with other nodes. Messages aren&#39;t necessarily sent over the network in-order, and out-of-order messages are put back together into the correct order for the receiver. Similar to memory managers, message managers are created lazily in response to messages being sent so that nodes that only communicate with their neighbors do not have to incur the overhead of maintaining unused message manager.</p>

<p>As a driving example let&#39;s look at how a task is sent to a remote node. This process starts in <code>Runtime::send_task</code>, and is probably a decision that some mapper has made. The first thing that happens is to check if the target processor is actually a local processor. Recall that local processors in the processor manager are eagerly instantiated. If it is local, then the method has a quick path that simply adds the task to the target processor&#39;s ready queue. If it isn&#39;t local, then the task is packaged up and sent to the remote node as a message.</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++"><span class="kt">void</span> <span class="n">Runtime</span><span class="o">::</span><span class="n">send_task</span><span class="p">(</span><span class="n">Processor</span> <span class="n">target</span><span class="p">,</span> <span class="n">TaskOp</span> <span class="o">*</span><span class="n">task</span><span class="p">)</span>
<span class="p">{</span>
  <span class="c1">// Check to see if the target processor is still local </span>
  <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">Processor</span><span class="p">,</span><span class="n">ProcessorManager</span><span class="o">*&gt;::</span><span class="n">const_iterator</span> <span class="n">finder</span> <span class="o">=</span> <span class="n">proc_managers</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">target</span><span class="p">);</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">finder</span> <span class="o">!=</span> <span class="n">proc_managers</span><span class="p">.</span><span class="n">end</span><span class="p">())</span> <span class="p">{</span>
    <span class="c1">// Update the current processor</span>
    <span class="n">task</span><span class="o">-&gt;</span><span class="n">current_proc</span> <span class="o">=</span> <span class="n">target</span><span class="p">;</span>
    <span class="n">finder</span><span class="o">-&gt;</span><span class="n">second</span><span class="o">-&gt;</span><span class="n">add_to_ready_queue</span><span class="p">(</span><span class="n">task</span><span class="p">,</span><span class="nb">false</span><span class="cm">/*previous failure*/</span><span class="p">);</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
<span class="p">...</span> <span class="c1">// see below</span>
  <span class="p">}</span>
<span class="p">}}</span>
</code></pre></div>
<p>The first thing that happens in the case that the target processor is remote is that we find the message manager for the remote node. Next a serializer is created that is used to package up the task into a buffer. Then ask the manager to send the task to the remote node using the <code>send_task</code> method.</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++">    <span class="n">MessageManager</span> <span class="o">*</span><span class="n">manager</span> <span class="o">=</span> <span class="n">find_messenger</span><span class="p">(</span><span class="n">target</span><span class="p">);</span>
    <span class="n">Serializer</span> <span class="n">rez</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="n">deactivate_task</span><span class="p">;</span>
    <span class="p">{</span>
      <span class="n">RezCheck</span> <span class="n">z</span><span class="p">(</span><span class="n">rez</span><span class="p">);</span>
      <span class="n">rez</span><span class="p">.</span><span class="n">serialize</span><span class="p">(</span><span class="n">target</span><span class="p">);</span>
      <span class="n">rez</span><span class="p">.</span><span class="n">serialize</span><span class="p">(</span><span class="n">task</span><span class="o">-&gt;</span><span class="n">get_task_kind</span><span class="p">());</span>
      <span class="n">deactivate_task</span> <span class="o">=</span> <span class="n">task</span><span class="o">-&gt;</span><span class="n">pack_task</span><span class="p">(</span><span class="n">rez</span><span class="p">,</span> <span class="n">target</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="c1">// Put it on the queue and send it</span>
    <span class="n">manager</span><span class="o">-&gt;</span><span class="n">send_task</span><span class="p">(</span><span class="n">rez</span><span class="p">,</span> <span class="nb">true</span><span class="cm">/*flush*/</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">deactivate_task</span><span class="p">)</span>
      <span class="n">task</span><span class="o">-&gt;</span><span class="n">deactivate</span><span class="p">();</span>
<span class="p">...</span>
</code></pre></div>
<p>The message manager calls <code>package_message</code> that adds some metadata describing the type of message. The <code>flush</code> parameter indicates that the message should be eagerly pushed to the remote node.</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++"><span class="kt">void</span> <span class="n">MessageManager</span><span class="o">::</span><span class="n">send_task</span><span class="p">(</span><span class="n">Serializer</span> <span class="o">&amp;</span><span class="n">rez</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">flush</span><span class="p">)</span>
<span class="p">{</span>
  <span class="n">package_message</span><span class="p">(</span><span class="n">rez</span><span class="p">,</span> <span class="n">TASK_MESSAGE</span><span class="p">,</span> <span class="n">flush</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>
<p>There is a call <code>send_xxx</code> (e.g. <code>send_task</code>) for each type of message. The <code>package_message</code> method is a generic method that handles the low-level details in a generic way. Essentially <code>package_message</code>
handles the packing of small messages into a single buffer, or splitting large messages across buffers. The typical buffer size is 8-16 KB, but is configurable. Check out the source for more details, but the next stop on the code walk occurs when <code>package_message</code> is ready to flush a buffer. To do this it calls <code>send_message</code>:</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++"><span class="kt">void</span> <span class="n">MessageManager</span><span class="o">::</span><span class="n">package_message</span><span class="p">(</span><span class="n">Serializer</span> <span class="o">&amp;</span><span class="n">rez</span><span class="p">,</span> <span class="n">MessageKind</span> <span class="n">k</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">flush</span><span class="p">)</span>
<span class="p">{</span>
<span class="p">...</span>
  <span class="k">while</span> <span class="p">(</span><span class="n">buffer_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">unsigned</span> <span class="n">remaining</span> <span class="o">=</span> <span class="n">sending_buffer_size</span> <span class="o">-</span> <span class="n">sending_index</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">remaining</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
      <span class="n">send_message</span><span class="p">(</span><span class="nb">false</span><span class="cm">/*complete*/</span><span class="p">);</span>
<span class="p">...</span>
</code></pre></div>
<p>The <code>send_message</code> routine is what handles the sending of messages and implements the logic for guaranteeing that messages are handled in order on the receiving node. When <code>send_message</code> is called it sends the buffer that the message manager maintains. What is interesting is that messages are sent by spawning a task on the target remote node, and the buffer is sent as a normal task argument:</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++"><span class="kt">void</span> <span class="n">MessageManager</span><span class="o">::</span><span class="n">send_message</span><span class="p">(</span><span class="kt">bool</span> <span class="n">complete</span><span class="p">)</span>
<span class="p">{</span>
<span class="p">...</span>
  <span class="c1">// Send the message</span>
  <span class="n">Event</span> <span class="n">next_event</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="n">spawn</span><span class="p">(</span><span class="n">HLR_TASK_ID</span><span class="p">,</span> <span class="n">sending_buffer</span><span class="p">,</span>
             <span class="n">sending_index</span><span class="p">,</span> <span class="n">last_message_event</span><span class="p">);</span>

  <span class="c1">// Update the event</span>
  <span class="n">last_message_event</span> <span class="o">=</span> <span class="n">next_event</span><span class="p">;</span>
<span class="p">...</span>
<span class="p">}</span>
</code></pre></div>
<p>Notice that the task that is launched uses the <code>last_message_event</code> as the precondition, and then updates the <code>last_message_event</code> variable when the return event from the <code>spawn</code> method which will trigger when the remote task completes, creating a chain of dependencies. In fact, when the message manager is first created <code>last_message_event</code> is initialized to the special <code>Event::NO_EVENT</code> that is always in a has-triggered state. This dependency chaining mechanism is what guarantees in-order processing of messages, even though messages may be sent out-of-order.</p>

<h1>Processor Manager</h1>

<p>The <code>ProcessorManager</code> tracks the low-level processors on the local node, and controls the rate of meta-work such as dependence analysis and mapping analysis. Unlike the <code>MemoryManager</code> and <code>MessageManager</code> processor managers are eagerly instantiated. The motivation for this is that we will likely want to use each of the local processors, and remote processors aren&#39;t tracked by the processor manager.</p>

<p>Processor managers are created at the same time that the runtime instance is created during the start-up / bootstrap phase, and occurs within the <code>Runtime::Runtime</code> constructor. Below we see a for loop that iterates over the <code>local_procs</code> set of processors, and creates a manager for each application processor (e.g. CPU or GPU), but does not create a manager for the utility processors.</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++"><span class="p">...</span>
<span class="k">for</span> <span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">set</span><span class="o">&lt;</span><span class="n">Processor</span><span class="o">&gt;::</span><span class="n">const_iterator</span> <span class="n">it</span> <span class="o">=</span> <span class="n">local_procs</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span>
    <span class="n">it</span> <span class="o">!=</span> <span class="n">local_procs</span><span class="p">.</span><span class="n">end</span><span class="p">();</span> <span class="n">it</span><span class="o">++</span><span class="p">)</span>
<span class="p">{</span>
  <span class="n">ProcessorManager</span> <span class="o">*</span><span class="n">manager</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ProcessorManager</span><span class="p">(</span><span class="o">*</span><span class="n">it</span><span class="p">,</span>
          <span class="n">machine</span><span class="o">-&gt;</span><span class="n">get_processor_kind</span><span class="p">(</span><span class="o">*</span><span class="n">it</span><span class="p">),</span> <span class="k">this</span><span class="p">,</span>
          <span class="n">superscalar_width</span><span class="p">,</span> <span class="n">DEFAULT_MAPPER_SLOTS</span><span class="p">,</span> 
          <span class="n">stealing_disabled</span><span class="p">,</span> <span class="n">machine</span><span class="o">-&gt;</span><span class="n">get_all_processors</span><span class="p">().</span><span class="n">size</span><span class="p">()</span><span class="o">-</span><span class="mi">1</span><span class="p">);</span>
  <span class="n">proc_managers</span><span class="p">[</span><span class="o">*</span><span class="n">it</span><span class="p">]</span> <span class="o">=</span> <span class="n">manager</span><span class="p">;</span>
<span class="p">...</span>
<span class="p">}</span>
</code></pre></div>
<p>The processor manager tracks all of the different types of mappers for a low-level processor. There is a simple interface for managing the set of mappers. When mappers are registered with the high-level runtime, processor managers eventually are responsible for handling that through a simple API:</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++"><span class="k">class</span> <span class="nc">ProcessorManager</span> <span class="p">{</span>
<span class="p">...</span>
  <span class="k">public</span><span class="o">:</span>
    <span class="kt">void</span> <span class="n">add_mapper</span><span class="p">(</span><span class="n">MapperID</span> <span class="n">mid</span><span class="p">,</span> <span class="n">Mapper</span> <span class="o">*</span><span class="n">m</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">check</span><span class="p">);</span>
    <span class="kt">void</span> <span class="nf">replace_default_mapper</span><span class="p">(</span><span class="n">Mapper</span> <span class="o">*</span><span class="n">m</span><span class="p">);</span>
    <span class="n">Mapper</span><span class="o">*</span> <span class="n">find_mapper</span><span class="p">(</span><span class="n">MapperID</span> <span class="n">mid</span><span class="p">)</span> <span class="k">const</span><span class="p">;</span> 
<span class="p">...</span>
  <span class="k">public</span><span class="o">:</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Mapper</span><span class="o">*&gt;</span> <span class="n">mapper_objects</span><span class="p">;</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Reservation</span><span class="o">&gt;</span> <span class="n">mapper_locks</span><span class="p">;</span>
<span class="p">...</span>
</code></pre></div>
<p>Each mapper is stored in the <code>mapper_objects</code> vector where its position in the vector is its ID. To avoid forcing developers to think about concurrency in the mappers, access to each mapper is serialized through a distinct lock stored in the <code>mapper_locks</code> vector. The runtime will automatically acquire the lock before dispatching calls to the mapper, and release the lock after the call.</p>

<p>The processor manager is responsible for invoking the mappers associated with its processor. There is a call with the naming pattern <code>invoke_mapper_xxx</code> for each method that the mapper interface supports:</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++"><span class="p">...</span>
  <span class="k">public</span><span class="o">:</span>
    <span class="c1">// Functions that perform mapping calls</span>
    <span class="kt">void</span> <span class="n">invoke_mapper_set_task_options</span><span class="p">(</span><span class="n">TaskOp</span> <span class="o">*</span><span class="n">task</span><span class="p">);</span>
    <span class="kt">void</span> <span class="nf">invoke_mapper_select_variant</span><span class="p">(</span><span class="n">TaskOp</span> <span class="o">*</span><span class="n">task</span><span class="p">);</span>
    <span class="kt">bool</span> <span class="nf">invoke_mapper_pre_map_task</span><span class="p">(</span><span class="n">TaskOp</span> <span class="o">*</span><span class="n">task</span><span class="p">);</span>
<span class="p">...</span>
</code></pre></div>
<p>Calls to mappers start at the high-level runtime (e.g. <code>invoke_mapper_map_task(Processor target, SingleTask *task);</code>) which will find the corresponding mapper and dispatch the call to the correct mapper.</p>

<p>One of the most important things that processor manager does is handle the scheduling of task execution so that operations like dependence analysis occur at good rates and at the right point in time. Recall the methods from previous classes such as <code>add_to_ready_queue</code>. Many of these calls as well as calls that mirror stages of the operational pipeline are bounced off of the processor manager in order for the processor manager to implement rate control:</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++"><span class="p">...</span>
  <span class="k">public</span><span class="o">:</span>
    <span class="kt">void</span> <span class="n">add_to_dependence_queue</span><span class="p">(</span><span class="n">Operation</span> <span class="o">*</span><span class="n">op</span><span class="p">);</span>
    <span class="kt">void</span> <span class="nf">add_to_ready_queue</span><span class="p">(</span><span class="n">TaskOp</span> <span class="o">*</span><span class="n">op</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">previous_failure</span><span class="p">);</span>
    <span class="kt">void</span> <span class="nf">add_to_local_ready_queue</span><span class="p">(</span><span class="n">Operation</span> <span class="o">*</span><span class="n">op</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">previous_failure</span><span class="p">);</span>
<span class="p">...</span>
</code></pre></div>
<p>When mappers are added to a processor manager data structures are expanded if necessary. For instance, the vector of mappers and corresponding locks may be resized:</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++"><span class="kt">void</span> <span class="n">ProcessorManager</span><span class="o">::</span><span class="n">add_mapper</span><span class="p">(</span><span class="n">MapperID</span> <span class="n">mid</span><span class="p">,</span> <span class="n">Mapper</span> <span class="o">*</span><span class="n">m</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">check</span><span class="p">)</span>
<span class="p">{</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">mid</span> <span class="o">&gt;=</span> <span class="n">mapper_objects</span><span class="p">.</span><span class="n">size</span><span class="p">())</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">old_size</span> <span class="o">=</span> <span class="n">mapper_objects</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
    <span class="n">mapper_objects</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">mid</span><span class="o">+</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">mapper_locks</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">mid</span><span class="o">+</span><span class="mi">1</span><span class="p">);</span>
    <span class="p">...</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="n">old_size</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="p">(</span><span class="n">mid</span><span class="o">+</span><span class="mi">1</span><span class="p">);</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">mapper_objects</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
      <span class="n">mapper_locks</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">destroy_reservation</span><span class="p">();</span>
      <span class="n">mapper_locks</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">Reservation</span><span class="o">::</span><span class="n">NO_RESERVATION</span><span class="p">;</span>
      <span class="p">...</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="n">mapper_locks</span><span class="p">[</span><span class="n">mid</span><span class="p">]</span> <span class="o">=</span> <span class="n">Reservation</span><span class="o">::</span><span class="n">create_reservation</span><span class="p">();</span>
  <span class="n">mapper_objects</span><span class="p">[</span><span class="n">mid</span><span class="p">]</span> <span class="o">=</span> <span class="n">m</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>
<p>The mapper with ID 0 is reserved for the default mapper, and the <code>ProcessorManager::replace_default_mapper</code> method can be used to change the default mapper:</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++"><span class="kt">void</span> <span class="n">ProcessorManager</span><span class="o">::</span><span class="n">replace_default_mapper</span><span class="p">(</span><span class="n">Mapper</span> <span class="o">*</span><span class="n">m</span><span class="p">)</span>
<span class="p">{</span>
  <span class="k">delete</span> <span class="n">mapper_objects</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
  <span class="n">mapper_objects</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">m</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>
<p>We can look now at how mappers are invoked by the processor manager. Here we&#39;ll look at <code>invoke_mapper_set_task_options</code>. We&#39;ll split this up because there are several different things going on here. There are two things mappers can do that drive the structure of this method. First, mappers can request that the mapper call be deferred to future time, and mappers can request that message be sent other mappers.</p>

<p>The first thing that happens is that we setup stack variables to track defer events as well as messages generated by the mapper:</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++"><span class="kt">void</span> <span class="n">ProcessorManager</span><span class="o">::</span><span class="n">invoke_mapper_set_task_options</span><span class="p">(</span><span class="n">TaskOp</span> <span class="o">*</span><span class="n">task</span><span class="p">)</span>
<span class="p">{</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">MapperMessage</span><span class="o">&gt;</span> <span class="n">messages</span><span class="p">;</span>
  <span class="n">Event</span> <span class="n">wait_on</span> <span class="o">=</span> <span class="n">defer_mapper_event</span><span class="p">[</span><span class="n">task</span><span class="o">-&gt;</span><span class="n">map_id</span><span class="p">];</span>
</code></pre></div>
<p>Next we enter a loop that executes until the mapper method has successfully executed. The first thing we do is check to see if we are deferring this event. If this is the first time through the loop, then it is likely that <code>wait_on</code> does not exist, so we do not wait on anything:</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++">  <span class="k">do</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">wait_on</span><span class="p">.</span><span class="n">exists</span><span class="p">())</span>
      <span class="n">wait_on</span><span class="p">.</span><span class="n">wait</span><span class="p">(</span><span class="nb">false</span><span class="cm">/*block*/</span><span class="p">);</span>
</code></pre></div>
<p>The next thing we do is invoke the mapper object after first obtaining the corresponding lock for that mapper.</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++">    <span class="n">AutoLock</span> <span class="nf">m_lock</span><span class="p">(</span><span class="n">mapper_locks</span><span class="p">[</span><span class="n">task</span><span class="o">-&gt;</span><span class="n">map_id</span><span class="p">]);</span>
    <span class="n">inside_mapper_call</span><span class="p">[</span><span class="n">task</span><span class="o">-&gt;</span><span class="n">map_id</span><span class="p">]</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span> 
    <span class="n">mapper_objects</span><span class="p">[</span><span class="n">task</span><span class="o">-&gt;</span><span class="n">map_id</span><span class="p">]</span><span class="o">-&gt;</span><span class="n">select_task_options</span><span class="p">(</span><span class="n">task</span><span class="p">);</span>
    <span class="n">inside_mapper_call</span><span class="p">[</span><span class="n">task</span><span class="o">-&gt;</span><span class="n">map_id</span><span class="p">]</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
</code></pre></div>
<p>Now there are two cases that we need to handle after invoking the mapper. The first is that the mapper could request that the invocation be deferred and restarted later:</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++">    <span class="k">if</span> <span class="p">(</span><span class="n">defer_mapper_event</span><span class="p">[</span><span class="n">task</span><span class="o">-&gt;</span><span class="n">map_id</span><span class="p">].</span><span class="n">exists</span><span class="p">())</span> <span class="p">{</span>
      <span class="n">wait_on</span> <span class="o">=</span> <span class="n">defer_mapper_event</span><span class="p">[</span><span class="n">task</span><span class="o">-&gt;</span><span class="n">map_id</span><span class="p">];</span>
      <span class="n">defer_mapper_event</span><span class="p">[</span><span class="n">task</span><span class="o">-&gt;</span><span class="n">map_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">Event</span><span class="o">::</span><span class="n">NO_EVENT</span><span class="p">;</span>
      <span class="k">continue</span><span class="p">;</span>
    <span class="p">}</span>
</code></pre></div>
<p>If the call is deferred then we return to the beginning of the loop and enter <code>wait_on.wait(..)</code> which will wait until the event has triggered, allowing the processor to be used by another task. The thread isn&#39;t blocked; in that sense this is a lot like a context switch in an operating system.</p>

<p>The other thing that a mapper may have done is to send messages. If messages were sent then we transfer them into our data structure on the stack:</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++">    <span class="n">AutoLock</span> <span class="nf">g_lock</span><span class="p">(</span><span class="n">message_lock</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">mapper_messages</span><span class="p">[</span><span class="n">task</span><span class="o">-&gt;</span><span class="n">map_id</span><span class="p">].</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
      <span class="n">messages</span> <span class="o">=</span> <span class="n">mapper_messages</span><span class="p">[</span><span class="n">task</span><span class="o">-&gt;</span><span class="n">map_id</span><span class="p">];</span>
      <span class="n">mapper_messages</span><span class="p">[</span><span class="n">task</span><span class="o">-&gt;</span><span class="n">map_id</span><span class="p">].</span><span class="n">clear</span><span class="p">();</span>
    <span class="p">}</span>
</code></pre></div>
<p>After the mapper call has been successfully invoked, we dispatch any messages that may have been queued up. This is done after all of the locks have been released to avoid deadlocks:</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++">    <span class="p">}</span> <span class="k">while</span> <span class="p">(</span><span class="n">wait_on</span><span class="p">.</span><span class="n">exists</span><span class="p">());</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">messages</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span>
      <span class="n">send_mapper_messages</span><span class="p">(</span><span class="n">task</span><span class="o">-&gt;</span><span class="n">map_id</span><span class="p">,</span> <span class="n">messages</span><span class="p">);</span>
</code></pre></div>
<p>The structure of this method is mirrored across each of the different mapper calls that the processor manager may invoke.</p>

<p>Let&#39;s take a look now at one of the components related to the operational pipeline. We&#39;ve seen <code>add_to_dependence_queue</code> before but now things should make more sense. First we setup a high-level runtime task that will perform the dependence analysis, and the manager is <code>this</code> processor manager.</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++"><span class="kt">void</span> <span class="n">ProcessorManager</span><span class="o">::</span><span class="n">add_to_dependence_queue</span><span class="p">(</span><span class="n">Operation</span> <span class="o">*</span><span class="n">op</span><span class="p">)</span>
<span class="p">{</span>
  <span class="n">DeferredTriggerArgs</span> <span class="n">args</span><span class="p">;</span>
  <span class="n">args</span><span class="p">.</span><span class="n">hlr_id</span> <span class="o">=</span> <span class="n">HLR_TRIGGER_DEPENDENCE_ID</span><span class="p">;</span>
  <span class="n">args</span><span class="p">.</span><span class="n">manager</span> <span class="o">=</span> <span class="k">this</span><span class="p">;</span>
  <span class="n">args</span><span class="p">.</span><span class="n">op</span> <span class="o">=</span> <span class="n">op</span><span class="p">;</span>
  <span class="p">...</span> <span class="c1">// see below</span>
</code></pre></div>
<p>Next we see how the processor manager is involved in enforcing the serial execution of dependence analysis. This analysis must take place serially within a context, which represents a parent and its sub-tasks. We grab the context from the parent and when we spawn the task we use the event stored in <code>dependence_preconditions</code> related to the context as a precondition. The precondition is then updated with the returned event. In this manner dependence analysis within a context is serialized, but analysis across contexts can occur in parallel.</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++">  <span class="n">ContextID</span> <span class="n">ctx_id</span> <span class="o">=</span> <span class="n">op</span><span class="o">-&gt;</span><span class="n">get_parent</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">get_context_id</span><span class="p">();</span>
  <span class="n">AutoLock</span> <span class="nf">d_lock</span><span class="p">(</span><span class="n">dependence_lock</span><span class="p">);</span>
  <span class="n">Event</span> <span class="n">next</span> <span class="o">=</span> <span class="n">utility_proc</span><span class="p">.</span><span class="n">spawn</span><span class="p">(</span><span class="n">HLR_TASK_ID</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">args</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">args</span><span class="p">),</span>
          <span class="n">dependence_preconditions</span><span class="p">[</span><span class="n">ctx_id</span><span class="p">]);</span>
  <span class="n">dependence_preconditions</span><span class="p">[</span><span class="n">ctx_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">next</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>
<p>Since execution occurs serially within a context and there are a small number of contexts, we don&#39;t see any example of rate-limiting here.</p>

<p>Next let&#39;s take a look at <code>add_to_local_ready_queue</code>. This is invoked when an operation has had its dependence analysis performed and is ready to be mapped. First thing we do is setup a high-level runtime task to schedule the mapping:</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++"><span class="kt">void</span> <span class="n">ProcessorManager</span><span class="o">::</span><span class="n">add_to_local_ready_queue</span><span class="p">(</span><span class="n">Operation</span> <span class="o">*</span><span class="n">op</span><span class="p">,</span> 
         <span class="kt">bool</span> <span class="n">prev_failure</span><span class="p">)</span>
<span class="p">{</span>
  <span class="n">TriggerOpArgs</span> <span class="n">args</span><span class="p">;</span>
  <span class="n">args</span><span class="p">.</span><span class="n">hlr_id</span> <span class="o">=</span> <span class="n">HLR_TRIGGER_OP_ID</span><span class="p">;</span>
  <span class="n">args</span><span class="p">.</span><span class="n">manager</span> <span class="o">=</span> <span class="k">this</span><span class="p">;</span>
  <span class="n">args</span><span class="p">.</span><span class="n">op</span> <span class="o">=</span> <span class="n">op</span><span class="p">;</span>
  <span class="p">...</span> <span class="c1">// see below</span>
</code></pre></div>
<p>Next there are two cases related to if there had been a previous failure. If there had been no previous failure (the common case) then we rate limit the scheduling of the task. If there was a previous failure we launch the task immediately because it is likely that other operations are waiting on the completion of the failed operation.</p>

<p>Here we get to see an example of how rate limiting is implemented. Notice the <code>local_scheduler_preconditions</code> structure that is indexed by <code>next_local_index</code>. This structure holds preconditions for the task being launched. Immediately after the task is launched we record the completion event in this structure in the next position, and loop the index back around if it reaches a maximum value. This effectively creates a set of dependence chains that result in rate limiting because of the serial nature of the dependence chains. The level of parallelism is controlled by the <code>superscalar_width</code> variable. Note that the these dependence chains are purely artificial.</p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++">  <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">prev_failure</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">AutoLock</span> <span class="n">l_lock</span><span class="p">(</span><span class="n">local_queue_lock</span><span class="p">);</span> 
    <span class="n">Event</span> <span class="n">next</span> <span class="o">=</span> <span class="n">utility_proc</span><span class="p">.</span><span class="n">spawn</span><span class="p">(</span><span class="n">HLR_TASK_ID</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">args</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">args</span><span class="p">),</span>
              <span class="n">local_scheduler_preconditions</span><span class="p">[</span><span class="n">next_local_index</span><span class="p">]);</span>

    <span class="n">local_scheduler_preconditions</span><span class="p">[</span><span class="n">next_local_index</span><span class="o">++</span><span class="p">]</span> <span class="o">=</span> <span class="n">next</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">next_local_index</span> <span class="o">==</span> <span class="n">superscalar_width</span><span class="p">)</span>
      <span class="n">next_local_index</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="p">}</span> <span class="k">else</span>
    <span class="n">utility_proc</span><span class="p">.</span><span class="n">spawn</span><span class="p">(</span><span class="n">HLR_TASK_ID</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">args</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">args</span><span class="p">));</span>
<span class="p">}</span>
</code></pre></div>
<p>If there had been a previous failure the task is launched immediately.</p>

  </article>

  <section id="disqus_thread"></section>

<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'noahdesugithubcom'; // required: replace example with your forum shortname
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">makedist</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li>makedist</li>
          <li><a href="mailto:noahwatkins@gmail.com">noahwatkins@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/noahdesu">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>

              <span class="username">noahdesu</span>
            </a>
          </li>
          

          
          <li>
            <a href="https://twitter.com/noahdesu">
              <span class="icon  icon--twitter">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                  c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
                </svg>
              </span>

              <span class="username">noahdesu</span>
            </a>
          </li>
          
        </ul>
      </div>

      <div class="footer-col  footer-col-3">
        <p class="text">Notes on programming, research, and other interests.
</p>
      </div>
    </div>

  </div>

</footer>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-37966177-1', 'auto');
  ga('send', 'pageview');
</script>

  </body>

</html>
